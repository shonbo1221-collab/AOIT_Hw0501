# Taiwan Weather Data Pipeline & AI Text Detection System

This project contains two main capabilities:
1. **Weather Data Pipeline** - Downloads and visualizes Taiwan weather data from CWA API
2. **AI Text Detection** - Classifies text as AI-generated or human-written

## ğŸŒ Live Demo

**Try the AI Text Detection System online:**  
ğŸ”— [https://aoithw0501-nappyp3vd7s2iqtocjzpwbl.streamlit.app/](https://aoithw0501-nappyp3vd7s2iqtocjzpwbl.streamlit.app/)

No installation required - just visit the link and start analyzing text!

## ğŸš€ Quick Start

### Installation

1. **Install Dependencies**
```bash
pip install -r requirements.txt
```

### AI Text Detection System

#### 1. Train the Model
```bash
python src/model/train.py
```

This will:
- Load training data from `data/train/`
- Train a TF-IDF + Logistic Regression classifier
- Save the model to `models/` directory
- Display training accuracy and top features

#### 2. Test the Model (Optional)
```bash
python src/model/test_model.py
```

This will evaluate the model on test data and show detailed predictions.

#### 3. Run the Web Application
```bash
streamlit run src/app.py
```

The application will open in your browser at `http://localhost:8501`

## ğŸ“ Project Structure

```
Hw05/
â”œâ”€â”€ data/                          # Training and test datasets
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ ai_generated.txt      # AI-generated training samples
â”‚   â”‚   â””â”€â”€ human_written.txt     # Human-written training samples
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ ai_generated.txt      # AI-generated test samples
â”‚       â””â”€â”€ human_written.txt     # Human-written test samples
â”œâ”€â”€ models/                        # Trained model files
â”‚   â”œâ”€â”€ model.pkl                 # Logistic Regression model
â”‚   â””â”€â”€ vectorizer.pkl            # TF-IDF vectorizer
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ train.py              # Model training script
â”‚   â”‚   â”œâ”€â”€ predict.py            # Prediction module
â”‚   â”‚   â””â”€â”€ test_model.py         # Model testing script
â”‚   â””â”€â”€ app.py                    # Streamlit web application
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                     # This file
```

## ğŸ¤– AI Text Detection Features

### How It Works
- **Feature Extraction**: TF-IDF (Term Frequency-Inverse Document Frequency)
- **Classification**: Logistic Regression
- **Vocabulary**: 5000 most important features
- **N-grams**: Unigrams and bigrams

### Web Interface Features
- ğŸ“ Text input area for analysis
- ğŸ¯ Probability breakdown (AI vs Human)
- ğŸ“Š Confidence meter with color coding
- ğŸ“š Sample texts for quick testing
- ğŸ“ˆ Text statistics (word count, character count)
- ğŸ’¡ Confidence level interpretation

### Usage Tips
- Enter at least 5 words for accurate results
- Longer texts generally produce better predictions
- Confidence scores indicate prediction certainty:
  - âœ… **High (80%+)**: Very reliable
  - âš ï¸ **Medium (60-80%)**: Moderately reliable
  - âŒ **Low (<60%)**: Less reliable

## ğŸŒ¤ï¸ Weather Data Pipeline

(Add your weather pipeline documentation here)

## ğŸ“Š Model Performance

The model is trained on sample datasets with the following characteristics:
- **Training Data**: 15 AI-generated + 15 human-written texts
- **Test Data**: 5 AI-generated + 5 human-written texts
- **Features**: TF-IDF with max 5000 features, unigrams + bigrams

> **Note**: This is a demonstration system. For production use, expand the dataset with more diverse examples.

## ğŸ› ï¸ Tech Stack

- **Python 3.x**
- **scikit-learn** - Machine learning
- **Streamlit** - Web interface
- **pandas** - Data processing
- **numpy** - Numerical operations
- **joblib** - Model serialization

## ğŸ“ Example Usage

### Command Line Prediction
```python
from src.model.predict import AITextDetector

detector = AITextDetector()
result = detector.predict_text("Your text here...")

print(f"Label: {result['label']}")
print(f"Confidence: {result['confidence']:.2f}%")
```

### Web Interface
1. Launch the app: `streamlit run src/app.py`
2. Enter or paste text in the text area
3. Click "Analyze Text"
4. View results with confidence scores and probabilities

## ğŸ” Testing

Run the test suite to evaluate model performance:
```bash
python src/model/test_model.py
```

This will show:
- Test accuracy
- Classification report (precision, recall, F1-score)
- Confusion matrix
- Detailed predictions for each test sample

## ğŸ“„ License

This project is for educational purposes.

## ğŸ‘¥ Contributors

- Your Name

## ğŸ™ Acknowledgments

- Central Weather Administration (CWA) for weather data API
- scikit-learn for machine learning tools
- Streamlit for the web framework
